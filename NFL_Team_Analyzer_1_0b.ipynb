{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NFL Team Analyzer 1.0b.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTGRvzNYNno3ukjXGKv8Q1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethanduncan65/NFL-Team-Analyzer/blob/main/NFL_Team_Analyzer_1_0b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fswTx3-MkP9L"
      },
      "source": [
        "Fantasy Football FLEX Production Analyzer 1.0b - Scraping data from ESPN\n",
        "\n",
        "Notes: \n",
        "\n",
        "*   This is for scraping the data and loading it into a local .csv file\n",
        "*   Runtime is approx. 1 min. for one week of games\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apxxAWvzzSQg"
      },
      "source": [
        "from bs4 import BeautifulSoup as soup  \n",
        "from urllib.request import urlopen as uReq  \n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V0n4S9WfX6I"
      },
      "source": [
        "# store all game_ids to current date\n",
        "game_ids_week1 = [401326322, 401326315, 401326308, 401326316, 401326317, 401326311, 401326318, 401326312, 401326309, 401326310, 401326314, 401326313, 401326319, 401326320, 401326323, 401326321]\n",
        "game_ids_week2 = [401326127, 401326129, 401326130, 401326131, 401326353, 401326354, 401326355, 401326356, 401326128, 401326132, 401326357, 401326358, 401326359, 401326360, 401326361, 401326362]\n",
        "game_ids_week3 = [401326363, 401326364, 401326365, 401326366, 401326372, 401326368, 401326369, 401326370, 401326371, 401326367, 401326373, 401326374, 401326375, 401326376, 401326377, 401326378]\n",
        "game_ids_testing = [401326358]\n",
        "\n",
        "#game_ids = game_ids_week1 + game_ids_week2 + game_ids_week3\n",
        "game_ids = game_ids_testing\n",
        "\n",
        "# go through each game and record stats & points allowed for both teams \n",
        "\n",
        "# create new df of average points allowed by each team\n",
        "\n",
        "# color code df based on their distance from the average"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0w-1hFzjHqH"
      },
      "source": [
        "df = pd.DataFrame(columns = ['Week', 'Team', 'Opp', 'QB Pts', 'RB Pts', 'WR Pts', 'TE Pts', 'Total Pts'],  index = range(0, (len(game_ids)*2)))\n",
        "\n",
        "Format = \"Standard\" #@param [\"Standard\", \"Half-PPR\", \"Full-PPR\"]\n",
        "format_dict = {'Standard': 0,\n",
        "               'Half-PPR': 0.5,\n",
        "               'Full-PPR': 1}\n",
        "PPR = format_dict.get(Format)\n",
        "i=0\n",
        "g=0\n",
        "\n",
        "while i<(len(game_ids)*2):\n",
        "  page_url = 'https://www.espn.com/nfl/boxscore/_/gameId/' + str(game_ids[g]) + ''\n",
        "  # ...\n",
        "  uClient = uReq(page_url)\n",
        "  # ...\n",
        "  page_soup = soup(uClient.read(), \"html.parser\")\n",
        "  uClient.close()\n",
        "\n",
        "  # tfx away team data\n",
        "  away_team = page_soup.find('div', {'class': \"team away\"})\n",
        "  away_team_name = away_team.find('span', {'class': \"abbrev\"})\n",
        "  away_team_name_str = away_team_name.get_text()\n",
        "  # tfx home team data\n",
        "  home_team = page_soup.find('div', {'class': \"team home\"})\n",
        "  home_team_name = home_team.find('span', {'class': \"abbrev\"})\n",
        "  home_team_name_str = home_team_name.get_text()\n",
        "\n",
        "  ### away team (column 1) scrape\n",
        "  # setup counter vars for point totals\n",
        "  away_qb_points = 0 \n",
        "  away_rb_points = 0 \n",
        "  away_wr_points = 0 \n",
        "  away_te_points = 0 \n",
        "  # add Team and Opp to df\n",
        "  df.at[i, 'Team'] = away_team_name_str\n",
        "  df.at[i, 'Opp'] = home_team_name_str\n",
        "  # select the away team data/containers\n",
        "  away_boxscore_div = page_soup.findAll('div', {'class': \"col column-one gamepackage-away-wrap\"})\n",
        "  # parse the Passing container\n",
        "  passing_away_data = away_boxscore_div[0].findAll('tr')\n",
        "  for q in range(1,len(passing_away_data)-1):\n",
        "    # scrape yards\n",
        "    q_player_yds = passing_away_data[q].find('td', {'class': \"yds\"}) \n",
        "    q_player_yds_str = q_player_yds.get_text()\n",
        "    q_player_yds_int = int(q_player_yds_str)\n",
        "    # scrape touchdowns\n",
        "    q_player_td = passing_away_data[q].find('td', {'class': \"td\"}) \n",
        "    q_player_td_str = q_player_td.get_text()\n",
        "    q_player_td_int = int(q_player_td_str)\n",
        "    # scrape interceptions\n",
        "    q_player_intr = passing_away_data[q].find('td', {'class': \"int\"}) \n",
        "    q_player_intr_str = q_player_intr.get_text()\n",
        "    q_player_intr_int = int(q_player_intr_str)\n",
        "    # tally points accordingly\n",
        "    away_qb_points+= 0.04*q_player_yds_int + 4*q_player_td_int\n",
        "    away_qb_points-= 2*q_player_intr_int\n",
        "  # parse the Rushing container\n",
        "  rushing_away_data = away_boxscore_div[1].findAll('tr')\n",
        "  for q in range(1,len(rushing_away_data)-1):\n",
        "    # scrape yards\n",
        "    q_player_yds = rushing_away_data[q].find('td', {'class': \"yds\"}) \n",
        "    q_player_yds_str = q_player_yds.get_text()\n",
        "    q_player_yds_int = int(q_player_yds_str)\n",
        "    # scrape touchdowns\n",
        "    q_player_td = rushing_away_data[q].find('td', {'class': \"td\"}) \n",
        "    q_player_td_str = q_player_td.get_text()\n",
        "    q_player_td_int = int(q_player_td_str)\n",
        "    # determine player's position\n",
        "    q_player_link = rushing_away_data[q].find('a', {'name': \"&lpos=nfl:game:boxscore:playercard\"})\n",
        "    q_player_link_str = str(q_player_link['href'])\n",
        "    player_page_url = q_player_link_str.split('_')[0] + 'bio/_' + q_player_link_str.split('_')[1]\n",
        "    player_uClient = uReq(player_page_url)\n",
        "    # ...\n",
        "    player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "    player_uClient.close()\n",
        "    #\n",
        "    player_position = player_page_soup.findAll('span', {'class': \"dib flex-uniform mr3 clr-gray-01\"})\n",
        "    player_position_str = player_position[1].get_text()\n",
        "    # depending on player's position, tally points accordingly\n",
        "    if player_position_str=='Quarterback':\n",
        "      away_qb_points+= 0.1*q_player_yds_int + 6*q_player_td_int\n",
        "    elif player_position_str=='Wide Receiver':\n",
        "      away_wr_points+= 0.1*q_player_yds_int + 6*q_player_td_int\n",
        "    else:\n",
        "      away_rb_points+= 0.1*q_player_yds_int + 6*q_player_td_int \n",
        "  # parse the Receiving container\n",
        "  receiving_away_data = away_boxscore_div[2].findAll('tr')\n",
        "  for q in range(1,len(receiving_away_data)-1):\n",
        "    # scrape receptions\n",
        "    q_player_rec = receiving_away_data[q].find('td', {'class': \"rec\"}) \n",
        "    q_player_rec_str = q_player_rec.get_text()\n",
        "    q_player_rec_int = int(q_player_rec_str)\n",
        "    # scrape yards\n",
        "    q_player_yds = receiving_away_data[q].find('td', {'class': \"yds\"}) \n",
        "    q_player_yds_str = q_player_yds.get_text()\n",
        "    q_player_yds_int = int(q_player_yds_str)\n",
        "    # scrape touchdowns\n",
        "    q_player_td = receiving_away_data[q].find('td', {'class': \"td\"}) \n",
        "    q_player_td_str = q_player_td.get_text()\n",
        "    q_player_td_int = int(q_player_td_str)\n",
        "    # determine player's position\n",
        "    q_player_link = receiving_away_data[q].find('a', {'name': \"&lpos=nfl:game:boxscore:playercard\"})\n",
        "    q_player_link_str = str(q_player_link['href'])\n",
        "    player_page_url = q_player_link_str.split('_')[0] + 'bio/_' + q_player_link_str.split('_')[1]\n",
        "    player_uClient = uReq(player_page_url)\n",
        "    # ...\n",
        "    player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "    player_uClient.close()\n",
        "    #\n",
        "    player_position = player_page_soup.findAll('span', {'class': \"dib flex-uniform mr3 clr-gray-01\"})\n",
        "    player_position_str = player_position[1].get_text()\n",
        "    # depending on player's position, tally points accordingly\n",
        "    if player_position_str=='Wide Receiver':\n",
        "      away_wr_points+= 0.1*q_player_yds_int + 6*q_player_td_int + PPR*q_player_rec_int\n",
        "    elif player_position_str=='Tight End':\n",
        "      away_te_points+= 0.1*q_player_yds_int + 6*q_player_td_int + PPR*q_player_rec_int\n",
        "    else:\n",
        "      away_rb_points+= 0.1*q_player_yds_int + 6*q_player_td_int + PPR*q_player_rec_int\n",
        "  # check for fumbles\n",
        "  fumbles_away_data = away_boxscore_div[3].findAll('tr')\n",
        "  # if there are fumbles, go through each one and adjust point totals accordingly \n",
        "  if len(fumbles_away_data)>2:\n",
        "    for q in range(1,len(fumbles_away_data)-1):\n",
        "      # scrape fumbles lost \n",
        "      q_player_fum = fumbles_away_data[q].find('td', {'class': \"lost\"}) \n",
        "      q_player_fum_str = q_player_fum.get_text()\n",
        "      q_player_fum_int = int(q_player_fum_str)\n",
        "      # if the fumble was lost (turnover) deduct points \n",
        "      if q_player_fum_int>0:\n",
        "        # determine player's position\n",
        "        q_player_link = fumbles_away_data[q].find('a', {'name': \"&lpos=nfl:game:boxscore:playercard\"})\n",
        "        q_player_link_str = str(q_player_link['href'])\n",
        "        player_page_url = q_player_link_str.split('_')[0] + 'bio/_' + q_player_link_str.split('_')[1]\n",
        "        player_uClient = uReq(player_page_url)\n",
        "        # ...\n",
        "        player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "        player_uClient.close()\n",
        "        #\n",
        "        player_position = player_page_soup.findAll('span', {'class': \"dib flex-uniform mr3 clr-gray-01\"})\n",
        "        player_position_str = player_position[1].get_text()\n",
        "        if player_position_str=='Quarterback':\n",
        "          away_qb_points-= 2*q_player_fum_int\n",
        "        if player_position_str=='Running Back':\n",
        "          away_rb_points-= 2*q_player_fum_int\n",
        "        if player_position_str=='Wide Receiver':\n",
        "          away_wr_points-= 2*q_player_fum_int\n",
        "        if player_position_str=='Tight End':\n",
        "          away_te_points-= 2*q_player_fum_int\n",
        "  # after scraping is complete for away team, add data to df\n",
        "  df.at[i, 'QB Pts'] = away_qb_points\n",
        "  df.at[i, 'RB Pts'] = away_rb_points\n",
        "  df.at[i, 'WR Pts'] = away_wr_points\n",
        "  df.at[i, 'TE Pts'] = away_te_points\n",
        "  df.at[i, 'Total Pts'] = away_qb_points + away_rb_points + away_wr_points + away_te_points\n",
        "  # ...\n",
        "  i+=1\n",
        "\n",
        "  ### home team (column 2) scrape\n",
        "  # setup counter vars for point totals\n",
        "  away_qb_points = 0 \n",
        "  away_rb_points = 0 \n",
        "  away_wr_points = 0 \n",
        "  away_te_points = 0 \n",
        "  # add Team and Opp to df\n",
        "  df.at[i, 'Team'] = home_team_name_str\n",
        "  df.at[i, 'Opp'] = away_team_name_str\n",
        "  # select the away team data/containers\n",
        "  away_boxscore_div = page_soup.findAll('div', {'class': \"col column-two gamepackage-home-wrap\"})\n",
        "  # parse the Passing container\n",
        "  passing_away_data = away_boxscore_div[0].findAll('tr')\n",
        "  for q in range(1,len(passing_away_data)-1):\n",
        "    # scrape yards\n",
        "    q_player_yds = passing_away_data[q].find('td', {'class': \"yds\"}) \n",
        "    q_player_yds_str = q_player_yds.get_text()\n",
        "    q_player_yds_int = int(q_player_yds_str)\n",
        "    # scrape touchdowns\n",
        "    q_player_td = passing_away_data[q].find('td', {'class': \"td\"}) \n",
        "    q_player_td_str = q_player_td.get_text()\n",
        "    q_player_td_int = int(q_player_td_str)\n",
        "    # scrape interceptions\n",
        "    q_player_intr = passing_away_data[q].find('td', {'class': \"int\"}) \n",
        "    q_player_intr_str = q_player_intr.get_text()\n",
        "    q_player_intr_int = int(q_player_intr_str)\n",
        "    # tally points accordingly\n",
        "    away_qb_points+= 0.04*q_player_yds_int + 4*q_player_td_int\n",
        "    away_qb_points-= 2*q_player_intr_int\n",
        "  # parse the Rushing container\n",
        "  rushing_away_data = away_boxscore_div[1].findAll('tr')\n",
        "  for q in range(1,len(rushing_away_data)-1):\n",
        "    # scrape yards\n",
        "    q_player_yds = rushing_away_data[q].find('td', {'class': \"yds\"}) \n",
        "    q_player_yds_str = q_player_yds.get_text()\n",
        "    q_player_yds_int = int(q_player_yds_str)\n",
        "    # scrape touchdowns\n",
        "    q_player_td = rushing_away_data[q].find('td', {'class': \"td\"}) \n",
        "    q_player_td_str = q_player_td.get_text()\n",
        "    q_player_td_int = int(q_player_td_str)\n",
        "    # determine player's position\n",
        "    q_player_link = rushing_away_data[q].find('a', {'name': \"&lpos=nfl:game:boxscore:playercard\"})\n",
        "    q_player_link_str = str(q_player_link['href'])\n",
        "    player_page_url = q_player_link_str.split('_')[0] + 'bio/_' + q_player_link_str.split('_')[1]\n",
        "    player_uClient = uReq(player_page_url)\n",
        "    # ...\n",
        "    player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "    player_uClient.close()\n",
        "    #\n",
        "    player_position = player_page_soup.findAll('span', {'class': \"dib flex-uniform mr3 clr-gray-01\"})\n",
        "    player_position_str = player_position[1].get_text()\n",
        "    # depending on player's position, tally points accordingly\n",
        "    if player_position_str=='Quarterback':\n",
        "      away_qb_points+= 0.1*q_player_yds_int + 6*q_player_td_int\n",
        "    elif player_position_str=='Wide Receiver':\n",
        "      away_wr_points+= 0.1*q_player_yds_int + 6*q_player_td_int\n",
        "    else:\n",
        "      away_rb_points+= 0.1*q_player_yds_int + 6*q_player_td_int \n",
        "  # parse the Receiving container\n",
        "  receiving_away_data = away_boxscore_div[2].findAll('tr')\n",
        "  for q in range(1,len(receiving_away_data)-1):\n",
        "    # scrape receptions\n",
        "    q_player_rec = receiving_away_data[q].find('td', {'class': \"rec\"}) \n",
        "    q_player_rec_str = q_player_rec.get_text()\n",
        "    q_player_rec_int = int(q_player_rec_str)\n",
        "    # scrape yards\n",
        "    q_player_yds = receiving_away_data[q].find('td', {'class': \"yds\"}) \n",
        "    q_player_yds_str = q_player_yds.get_text()\n",
        "    q_player_yds_int = int(q_player_yds_str)\n",
        "    # scrape touchdowns\n",
        "    q_player_td = receiving_away_data[q].find('td', {'class': \"td\"}) \n",
        "    q_player_td_str = q_player_td.get_text()\n",
        "    q_player_td_int = int(q_player_td_str)\n",
        "    # determine player's position\n",
        "    q_player_link = receiving_away_data[q].find('a', {'name': \"&lpos=nfl:game:boxscore:playercard\"})\n",
        "    q_player_link_str = str(q_player_link['href'])\n",
        "    player_page_url = q_player_link_str.split('_')[0] + 'bio/_' + q_player_link_str.split('_')[1]\n",
        "    player_uClient = uReq(player_page_url)\n",
        "    # ...\n",
        "    player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "    player_uClient.close()\n",
        "    #\n",
        "    player_position = player_page_soup.findAll('span', {'class': \"dib flex-uniform mr3 clr-gray-01\"})\n",
        "    player_position_str = player_position[1].get_text()\n",
        "    # depending on player's position, tally points accordingly\n",
        "    if player_position_str=='Wide Receiver':\n",
        "      away_wr_points+= 0.1*q_player_yds_int + 6*q_player_td_int + PPR*q_player_rec_int\n",
        "    elif player_position_str=='Tight End':\n",
        "      away_te_points+= 0.1*q_player_yds_int + 6*q_player_td_int + PPR*q_player_rec_int\n",
        "    else:\n",
        "      away_rb_points+= 0.1*q_player_yds_int + 6*q_player_td_int + PPR*q_player_rec_int\n",
        "  # check for fumbles\n",
        "  fumbles_away_data = away_boxscore_div[3].findAll('tr')\n",
        "  # if there are fumbles, go through each one and adjust point totals accordingly \n",
        "  if len(fumbles_away_data)>2:\n",
        "    for q in range(1,len(fumbles_away_data)-1):\n",
        "      # scrape fumbles lost \n",
        "      q_player_fum = fumbles_away_data[q].find('td', {'class': \"lost\"}) \n",
        "      q_player_fum_str = q_player_fum.get_text()\n",
        "      q_player_fum_int = int(q_player_fum_str)\n",
        "      # if the fumble was lost (turnover) deduct points \n",
        "      if q_player_fum_int>0:\n",
        "        # determine player's position\n",
        "        q_player_link = fumbles_away_data[q].find('a', {'name': \"&lpos=nfl:game:boxscore:playercard\"})\n",
        "        q_player_link_str = str(q_player_link['href'])\n",
        "        player_page_url = q_player_link_str.split('_')[0] + 'bio/_' + q_player_link_str.split('_')[1]\n",
        "        player_uClient = uReq(player_page_url)\n",
        "        # ...\n",
        "        player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "        player_uClient.close()\n",
        "        #\n",
        "        player_position = player_page_soup.findAll('span', {'class': \"dib flex-uniform mr3 clr-gray-01\"})\n",
        "        player_position_str = player_position[1].get_text()\n",
        "        if player_position_str=='Quarterback':\n",
        "          away_qb_points-= 2*q_player_fum_int\n",
        "        if player_position_str=='Running Back':\n",
        "          away_rb_points-= 2*q_player_fum_int\n",
        "        if player_position_str=='Wide Receiver':\n",
        "          away_wr_points-= 2*q_player_fum_int\n",
        "        if player_position_str=='Tight End':\n",
        "          away_te_points-= 2*q_player_fum_int\n",
        "  # after scraping is complete for away team, add data to df\n",
        "  df.at[i, 'QB Pts'] = away_qb_points\n",
        "  df.at[i, 'RB Pts'] = away_rb_points\n",
        "  df.at[i, 'WR Pts'] = away_wr_points\n",
        "  df.at[i, 'TE Pts'] = away_te_points\n",
        "  df.at[i, 'Total Pts'] = away_qb_points + away_rb_points + away_wr_points + away_te_points\n",
        "  # ... \n",
        "  i+=1\n",
        "  g+=1\n",
        "\n",
        "# preview df\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BavPpY0LiQ6"
      },
      "source": [
        "print(passing_away_data[1].find('td', {'class': \"yds\"}))\n",
        "print(passing_away_data[1].find('td', {'class': \"td\"}))\n",
        "print(passing_away_data[1].find('td', {'class': \"int\"}))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqrOsZnPNg9c"
      },
      "source": [
        "sumX = 0.04*276 + 4*5 + 0.1*6 -2\n",
        "print(sumX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4BAJisbL64w"
      },
      "source": [
        "df.to_csv('Season Log_standard.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYLVrlOQYT6R"
      },
      "source": [
        "df_seasonLog = pd.read_csv('Season Log_standard.csv')\n",
        "df_seasonLog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_b9w3MM8Yjm"
      },
      "source": [
        "# remove duplicates to create list of all teams\n",
        "teams = list(set(df_seasonLog['Opp']))\n",
        "teams\n",
        "\n",
        "# calculate averages for each team \n",
        "for t in range(0,len(teams)):\n",
        "  df_t_team = df_seasonLog[df_seasonLog.Opp==teams[t]]\n",
        "  t_avg_qb_pts = df_t_team['QB Pts'].mean()\n",
        "\n",
        "# standardize the points ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl8r2sqCZOtz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NJlyOfBZOmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-Y7WKvcZOgK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YmbW1XML6wr"
      },
      "source": [
        "df_team = df[df.Opp=='SEA']\n",
        "df_team"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWAuRdMo3uwp"
      },
      "source": [
        "df_team['QB Pts'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BPAOebyKKBX"
      },
      "source": [
        "df_ptsAllowed = pd.DataFrame(columns = ['Week', 'Team', 'QB Pts', 'RB Pts', 'WR Pts', 'TE Pts', 'Total Pts'],  index = range(0, 32))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEf7g76boHk6"
      },
      "source": [
        "fumbles_away_data = away_boxscore_div[3].findAll('tr')\n",
        "len(fumbles_away_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwEpUOnmrefY"
      },
      "source": [
        "wr_data = away_boxscore_div[2].findAll('tr')\n",
        "#wr_data[2]\n",
        "\n",
        "# receiving scrape\n",
        "for q in range(1,len(wr_data)-1):\n",
        "  # scrape receptions\n",
        "  q_player_rec = wr_data[q].find('td', {'class': \"rec\"}) \n",
        "  q_player_rec_str = q_player_rec.get_text()\n",
        "  q_player_rec_int = int(q_player_rec_str)\n",
        "  # scrape yards\n",
        "  q_player_yds = wr_data[q].find('td', {'class': \"yds\"}) \n",
        "  q_player_yds_str = q_player_yds.get_text()\n",
        "  q_player_yds_int = int(q_player_yds_str)\n",
        "  # scrape touchdowns\n",
        "  q_player_td = wr_data[q].find('td', {'class': \"td\"}) \n",
        "  q_player_td_str = q_player_td.get_text()\n",
        "  q_player_td_int = int(q_player_td_str)\n",
        "  # determine player's position\n",
        "  q_player_link = wr_data[q].find('a', {'name': \"&lpos=nfl:game:boxscore:playercard\"})\n",
        "  q_player_link_str = str(q_player_link['href'])\n",
        "  player_page_url = q_player_link_str.split('_')[0] + 'bio/_' + q_player_link_str.split('_')[1]\n",
        "  player_uClient = uReq(player_page_url)\n",
        "  # ...\n",
        "  player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "  player_uClient.close()\n",
        "  #\n",
        "  player_position = player_page_soup.findAll('span', {'class': \"dib flex-uniform mr3 clr-gray-01\"})\n",
        "  player_position_str = player_position[1].get_text()\n",
        "  print(player_position_str)\n",
        "\n",
        "  #print(q_player_link['href'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GCXuiKMw-ny"
      },
      "source": [
        "q_player_rec = wr_data[2].find('td', {'class': \"yds\"}) \n",
        "q_player_rec_str = q_player_rec.get_text()\n",
        "\n",
        "q_player_rec_str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCOlun8pu1Wq"
      },
      "source": [
        "player_page_url = 'https://www.espn.com/nfl/player/gamelog/_/id/4047650/dk-metcalf'\n",
        "# ...\n",
        "player_uClient = uReq(player_page_url)\n",
        "# ...\n",
        "player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "player_uClient.close()\n",
        "\n",
        "player_stats = player_page_soup.findAll('td', {'class': \"Table__TD\"})\n",
        "player_position = player_page_soup.findAll('th', {'class': \"tc Table__TH\"})\n",
        "player_position_str = player_position[0].get_text()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2wRmgwv49hq"
      },
      "source": [
        "df_player = pd.DataFrame(columns = ['Week', 'Team', 'Opp', 'Tgt', 'Rec', 'Pass Yds', 'Pass TD', 'Car', 'Rush Yds', 'Rush TD', 'Points', '% Share'],  index = range(0, numWeeks))\n",
        "\n",
        "player_page_url = 'https://www.espn.com/nfl/player/gamelog/_/id/4047650/dk-metcalf'\n",
        "# ...\n",
        "player_uClient = uReq(player_page_url)\n",
        "# ...\n",
        "player_page_soup = soup(player_uClient.read(), \"html.parser\")\n",
        "player_uClient.close()\n",
        "\n",
        "#player_stats = player_page_soup.find('tr', {'class': \"Table__TR Table__TR--sm Table__even\"})\n",
        "#player_statsX = player_page_soup.findAll('td', {'class': \"Table__TD\"})\n",
        "#player_statsX[0].get_text()\n",
        "#player_statsX[4].get_text()\n",
        "#player_statsX[36].get_text()\n",
        "\n",
        "\n",
        "\n",
        "# determine if player is RB or WR/TE\n",
        "player_stats = player_page_soup.findAll('td', {'class': \"Table__TD\"})\n",
        "player_position = player_page_soup.findAll('th', {'class': \"tc Table__TH\"})\n",
        "player_position_str = player_position[0].get_text()\n",
        "if player_position_str=='Rushing':\n",
        "  #\n",
        "  k=0\n",
        "  for r in range(0, numWeeks):\n",
        "    # add week, team, opp\n",
        "    df_player.at[r, 'Tgt'] = player_stats[9+k].get_text()\n",
        "    df_player.at[r, 'Rec'] = player_stats[8+k].get_text()\n",
        "    df_player.at[r, 'Pass Yds'] = player_stats[10+k].get_text()\n",
        "    df_player.at[r, 'Pass TD'] = player_stats[9+k].get_text()\n",
        "    df_player.at[r, 'Car'] = player_stats[3+k].get_text()\n",
        "    df_player.at[r, 'Rush Yds'] = player_stats[4+k].get_text()\n",
        "    df_player.at[r, 'Rush TD'] = player_stats[6+k].get_text()\n",
        "    k+=18\n",
        "else:\n",
        "  #\n",
        "  k=0\n",
        "  for r in range(0, numWeeks):\n",
        "    # add week, team, opp\n",
        "    df_player.at[r, 'Tgt'] = player_stats[4+k].get_text()\n",
        "    df_player.at[r, 'Rec'] = player_stats[3+k].get_text()\n",
        "    df_player.at[r, 'Pass Yds'] = player_stats[5+k].get_text()\n",
        "    df_player.at[r, 'Pass TD'] = player_stats[7+k].get_text()\n",
        "    df_player.at[r, 'Car'] = player_stats[9+k].get_text()\n",
        "    df_player.at[r, 'Rush Yds'] = player_stats[10+k].get_text()\n",
        "    df_player.at[r, 'Rush TD'] = player_stats[13+k].get_text()\n",
        "    k+=18\n",
        "\n",
        "# reverse order of df_player to align with format of df's below"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ7vXpdWHkcp"
      },
      "source": [
        "Team = \"Seattle Seahawks\" #@param [\"Seattle Seahawks\", \"San Francisco 49ers\"]\n",
        "vsTeam = \"San Francisco 49ers\" #@param [\"Seattle Seahawks\", \"San Francisco 49ers\"]\n",
        "Format = \"Standard\" #@param [\"Standard\", \"Half-PPR\", \"Full-PPR\"]\n",
        "team_sched_dict = {\"Seattle Seahawks\": [401326318, 401326360, 401326376],\n",
        "                   \"San Francisco 49ers\": [401326317, 401326355, 401326377]}\n",
        "game_ids = team_sched_dict.get(Team)\n",
        "vs_game_ids = team_sched_dict.get(vsTeam)\n",
        "\n",
        "team_name_dict = {\"Seattle Seahawks\": 'SEA',\n",
        "                  \"San Francisco 49ers\": 'SF'}\n",
        "team_abbrev = team_name_dict.get(Team)\n",
        "vs_team_abbrev = team_name_dict.get(vsTeam)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}